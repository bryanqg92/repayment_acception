{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps Workflow con MLflow\n",
    "\n",
    "## 1. Importar librerías y configuración de MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lean/miniconda3/envs/mlops_course/lib/python3.9/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/lean/miniconda3/envs/mlops_course/lib/python3.9/site-packages/pydantic/_internal/_config.py:322: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar y preprocesar la data \n",
    "\n",
    "este es un hipotetico paso que se realiza pero para efectos practicos cargamos las bases de train y test que se preprocesaron en la notebook e2e_construccion.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenar el modelo con MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lean/miniconda3/envs/mlops_course/lib/python3.9/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9043182186672432\n",
      "Precision: 0.9051112454236506\n",
      "Recall: 0.9043182186672432\n",
      "F1 Score: 0.9041625339127102\n",
      "Modelo entrenado y registrado en MLflow.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Repayment_plan_acceptance\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    n_estimators = 100\n",
    "    max_depth = None\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Registrar parámetros\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "\n",
    "    # Registrar métricas\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    # Registrar el modelo\n",
    "    mlflow.sklearn.log_model(rf, \"random_forest_model\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    #pd.DataFrame(y_pred, columns=['predictions']).to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"Modelo entrenado y registrado en MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir el pipeline del modelo para inferencia\n",
    "\n",
    "- Extraer los datos de las diferentes fuente de datos.\n",
    "- preprocesar y transformar los datos numéricos y categóricos, recordar que primero de hace una transformación logartimica y luego una transformación de normalización.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "df_demografico = pd.read_csv('processed_files/demografica.csv')\n",
    "df_historic = pd.read_csv('processed_files/historic.csv')\n",
    "df_evaluation = pd.read_csv('files/prueba_op_base_pivot_var_rpta_alt_enmascarado_oot.csv')\n",
    "\n",
    "class DataExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "    \n",
    "        results = []\n",
    "        for i in range(len(X)):\n",
    "            nit_enmascarado = X.iloc[i]['nit_enmascarado']\n",
    "            num_oblig_enmascarado = X.iloc[i]['num_oblig_enmascarado']\n",
    "            \n",
    "            tot_patrimonio = df_demografico['tot_patrimonio'][(df_demografico['nit_enmascarado'] == nit_enmascarado)].median()\n",
    "            total_ing = df_demografico['total_ing'][(df_demografico['nit_enmascarado'] == nit_enmascarado)].median()\n",
    "            min_mora = df_historic['dias_mora'][(df_historic['nit_enmascarado'] == nit_enmascarado) & (df_historic['num_oblig_enmascarado'] == num_oblig_enmascarado)].min()\n",
    "            max_mora = df_historic['dias_mora'][(df_historic['nit_enmascarado'] == nit_enmascarado) & (df_historic['num_oblig_enmascarado'] == num_oblig_enmascarado)].max()\n",
    "            valor_cuota_mes = df_historic['valor_cuota_mes'][(df_historic['nit_enmascarado'] == nit_enmascarado) & (df_historic['num_oblig_enmascarado'] == num_oblig_enmascarado)].median()\n",
    "            producto = df_historic['producto'][(df_historic['nit_enmascarado'] == nit_enmascarado) & (df_historic['num_oblig_enmascarado'] == num_oblig_enmascarado)].mode()[0]\n",
    "            moda_marca_pago = df_historic['marca_pago'][(df_historic['nit_enmascarado'] == nit_enmascarado) & (df_historic['num_oblig_enmascarado'] == num_oblig_enmascarado)].mode()[0]\n",
    "            \n",
    "            data =[tot_patrimonio, total_ing, min_mora, max_mora, valor_cuota_mes, producto, moda_marca_pago]\n",
    "            results.append(data)\n",
    "        \n",
    "        return np.array(results)\n",
    "\n",
    "def log_trans(valor):\n",
    "    return np.log(valor + 1)\n",
    "\n",
    "numeric_features = ['tot_patrimonio', 'total_ing', 'min_mora', 'max_mora', 'valor_cuota_mes']\n",
    "categorical_features = ['producto', 'marca_pago']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('log', FunctionTransformer(log_trans, validate=False)),\n",
    "            ('scaler', MinMaxScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "model = Pipeline([\n",
    "    ('data_extraction', DataExtractor()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "experiments = client.list_experiments(view_type=ViewType.ACTIVE_ONLY)\n",
    "all_runs = []\n",
    "\n",
    "for experiment in experiments:\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        filter_string=\"\",\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=500,\n",
    "        order_by=[\"metrics.f1_score DESC\"]\n",
    "    )\n",
    "    all_runs.extend(runs)\n",
    "\n",
    "if all_runs:\n",
    "    best_run = all_runs[0]\n",
    "    print(f\"El mejor run tiene un f1_score de: {best_run.data.metrics['f1_score']}\")\n",
    "\n",
    "    # Registrar y promover el modelo asociado al mejor run\n",
    "    model_uri = f\"runs:/{best_run.info.run_id}/random_forest_model\"\n",
    "    model_version = mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "    # Promover a producción\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=model_version.version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "\n",
    "    print(f\"Modelo promovido a producción: {model_name} v{model_version.version}\")\n",
    "else:\n",
    "    print(\"No se encontraron experimentos con métricas de f1_score.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
